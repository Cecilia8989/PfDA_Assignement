{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center>Programming for Data Analytics - Project 1</center></h3>\n",
    "<h1><center>Fisic and sexual violance against women in italy</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project focuses on assessing the probability that a woman in Italy, aged between 15 and 70, will experience physical/sexual violence by her partner/ex-partner in her lifetime. \n",
    "To achieve this, various datasets and microdatasets from the [ISTAT [1]](https://esploradati.istat.it/databrowser/#/) have been utilized.\n",
    "\n",
    "ISTAT, the Italian National Institute of Statistics (Istituto Nazionale di Statistica), operates as the official statistical agency of Italy, functioning under the supervision of the Italian Ministry of Economy and Finance. It is tasked with collecting, producing, and disseminating statistical information across diverse aspects of Italian society and the economy.\n",
    "\n",
    "The study considers four variables, and a dataset has been constructed to explore, based on each combination of these variables, the probability and likelihood of a woman experiencing physical/sexual violence by her partner/ex-partner in her lifetime.\n",
    "\n",
    "The four variables under consideration are:\n",
    "\n",
    "1. Area of residence\n",
    "2. Level of education\n",
    "3. Marital status\n",
    "4. Occupational level\n",
    "\n",
    "By combining the probabilities associated with each variable (e.g., the probability that a woman with a particular level of education will endure violence), the project aims to calculate, using a binomial distribution, whether the event will occur or not. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import the needed library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first stap I would like import the library that will be needed in the project. \n",
    "they are:\n",
    "\n",
    "- **pandas**: This library is widely used for data manipulation and analysis. It provides data structures like DataFrame for efficient data manipulation with integrated indexing. Pandas is particularly useful for handling structured data and working with time-series data numpy [[]](https://pandas.pydata.org/).\n",
    "- **numpy**: Numpy is a powerful library for numerical operations in Python. It provides support for large, multi-dimensional arrays and matrices, along with mathematical functions to operate on these elements. Many other scientific and data analysis libraries in Python, including pandas, are built on top of NumPy [[]](https://numpy.org/).\n",
    "- **seaborn**: Seaborn is a statistical data visualization library based on Matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics. Seaborn is particularly useful for creating informative and visually appealing statistical graphics, making it easier to explore and understand complex datasets [[]](https://seaborn.pydata.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the pandas library for data manipulation and analysis\n",
    "import pandas as pd\n",
    "# Importing the numpy library for numerical operations and array manipulations\n",
    "import numpy as np\n",
    "# Importing the seaborn library for data visualization\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Region of resident**\n",
    "\n",
    "The **region of residence** plays a significant role in analyzing the risk of violence against women. It is often observed that the poorest regions are associated with higher instances of sexual and physical violence against women. This correlation can be attributed to a combination of economic and cultural factors. Women residing in economically disadvantaged regions face greater challenges in personal development, have limited access to resources for preventing and escaping violence, and may be influenced by a cultural environment that tolerates such phenomena. This interconnectedness creates a complex scenario where the acceptance of violence against women becomes more prevalent [[]](https://www.ladynomics.it/conoscere-la-violenza-economica-2a-puntata-la-poverta/).\n",
    "\n",
    "Italy can be divided into three main regions: **North, South (including islands), and Central**. Historically, the Northern region has exhibited higher economic development, providing more employment and developmental opportunities for its population. Conversely, the South is acknowledged as the economically poorest area of Italy, characterized by a significantly affected employment rate and a culture that mirrors this economic situation. The Central region falls in between these extremes.\n",
    "\n",
    "Given these historical and economic disparities, we can anticipate a higher impact of violence against women in the South compared to the North. The socio-economic conditions, employment challenges, and cultural influences prevalent in the South may contribute to an environment where incidents of violence against women are more pronounced. \n",
    "\n",
    "In the process of creating the database:\n",
    "1.  our first step involves determining the **probability of women aged 15 to 70 experiencing violence segmented by region**, considering the distinct characteristics of the North, South, and Central regions.\n",
    "2. Following this, we will construct an initial dataframe comprising **200 randomly generated entries**, strategically distributed among the three regions: North, South, and Central.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **3.1 Regional Disparities: Probability of Violence Against Women Across Italy's Main Regions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a preliminary step, we need to calculate the probability that a woman residing in the South, North, or Centre will experience violence from a partner or ex-partner over her lifetime.\n",
    "\n",
    "To achieve this, ISTAT has published microdatasets that explore the impact of various variables on violence against women. Specifically, there is a dataset available on the website that connects the region of residence with the percentage of women who endure violence [[]](https://esploradati.istat.it/databrowser/#/it/dw/categories/IT1,Z0840JUS,1.0/JUS_VIOLENCE).\n",
    "\n",
    "Our next tasks involve importing the dataset, exploring its contents, and performing data cleaning and manipulation to derive the probability of violence associated with each region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Import the dataset\n",
    "\n",
    "The dataseset has been imported from the ISTAT [[A]](https://esploradati.istat.it/databrowser/#/it/dw/categories/IT1,Z0840JUS,1.0/JUS_VIOLENCE) as a CSV and saved on the repository. The folder **DataSet** contain all the dataset used on the current project. We will them use the **read_csv()** function to import it as a dataframe unsing pandas [[]](https://www.w3schools.com/python/pandas/pandas_csv.asp). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset on violence divided per region\n",
    "violence_by_region = pd.read_csv('DataSet/Violence divided per region.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Ceck missing value \n",
    "\n",
    "We can now check for missing values using the isnull() function [[]](https://note.nkmk.me/en/python-pandas-nan-judge-count/). The dataset reveals missing values only in the 'flag' and 'flag codeds' columns. However, upon further inspection of the dataset, it is evident that these columns are not relevant, as they are empty. Therefore, we will be able after to drop those columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Missing values for \"violence by region\" ==\n",
      "ITTER107                 0\n",
      "Territory                0\n",
      "TIPO_DATO_VIOLENZA       0\n",
      "Data type                0\n",
      "TIPOAUT                  0\n",
      "Perpetrator              0\n",
      "TIPOVIOLENZA             0\n",
      "Type of violence         0\n",
      "TIME                     0\n",
      "Select time              0\n",
      "Value                    0\n",
      "Flag Codes            1204\n",
      "Flags                 1204\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Printing a header to indicate the section related to missing values for violence per region\n",
    "print(f'== Missing values for \"violence by region\" ==')\n",
    "# Using the isnull() function to check for missing values and summing them up\n",
    "missing_values_count = violence_by_region.isnull().sum()\n",
    "# Printing the count of missing values for each column in the dataset\n",
    "print(missing_values_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Data exploration and cleaning \n",
    "\n",
    "*Sampling the dataset*\n",
    "\n",
    "To begin our dataset observation and identify columns and rows for removal, we can utilize the **sample()** function [[]](https://www.geeksforgeeks.org/python-pandas-dataframe-sample/). This function will display a random selection of rows from the specified dataset, aiding us in assessing the data and making informed decisions on what to remove.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Sample lines from \"violence by region\" ==\n",
      "     ITTER107  Territory TIPO_DATO_VIOLENZA  \\\n",
      "812      ITF1    Abruzzo     W16_70_CFP_M12   \n",
      "243      ITC4  Lombardia     W16_70_CFP_M12   \n",
      "1043     ITF6   Calabria      W16_70_PNP_LT   \n",
      "428      ITD3     Veneto      W16_70_PNP_Y5   \n",
      "216      ITC4  Lombardia      W16_70_PNP_Y5   \n",
      "\n",
      "                                              Data type       TIPOAUT  \\\n",
      "812   women aged 16-70 years who have suffered viole...  CURR_OR_FORM   \n",
      "243   women aged 16-70 years who have suffered viole...  CURR_OR_FORM   \n",
      "1043  women aged 16-70 years who have suffered viole...     ANY_P_NOP   \n",
      "428   women aged 16-70 years who have suffered viole...           NOP   \n",
      "216   women aged 16-70 years who have suffered viole...     ANY_P_NOP   \n",
      "\n",
      "                            Perpetrator TIPOVIOLENZA         Type of violence  \\\n",
      "812   current partner or former partner        PHSEX       physical or sexual   \n",
      "243   current partner or former partner  RAPE_OR_ATT   rape or attempted rape   \n",
      "1043  any man (partner and non-partner)  RAPE_OR_ATT   rape or attempted rape   \n",
      "428                     man non-partner        PHSEX       physical or sexual   \n",
      "216   any man (partner and non-partner)        PHSEX       physical or sexual   \n",
      "\n",
      "      TIME  Select time  Value  Flag Codes  Flags  \n",
      "812   2014         2014    3.8         NaN    NaN  \n",
      "243   2014         2014    0.3         NaN    NaN  \n",
      "1043  2014         2014    4.1         NaN    NaN  \n",
      "428   2014         2014    6.3         NaN    NaN  \n",
      "216   2014         2014   10.7         NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "# Printing a header to indicate that the following lines are a sample from the \"violence by region\" dataset\n",
    "print(f'== Sample lines from \"violence by region\" ==')\n",
    "# Using the sample() function to display a random selection of 5 rows from the dataset\n",
    "sample_data = violence_by_region.sample(5)\n",
    "# Printing the sampled data\n",
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dropping useless columns*\n",
    "\n",
    "After observing the dataset, it appears that most columns contain duplicate or irrelevant data. Consequently, our initial step involves dropping empty or redundant columns using the **drop()** function. This will be done after defining a list of columns to be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_removed = ['ITTER107', 'TIPO_DATO_VIOLENZA', 'TIPOAUT', 'TIPOVIOLENZA',\n",
    "       'Select time', 'Flag Codes', 'Flags']\n",
    "\n",
    "# Remove the specified columns from the 'Instruction_level_italy' DataFrame\n",
    "violence_per_region = violence_per_region.drop(columns=columns_to_be_removed)\n",
    "\n",
    "# Renaming columns in a Pandas DataFrame\n",
    "violence_per_region.rename(columns={\"TIME\": \"Year\", 'Value':'%_Violence_Territory'},inplace=True)\n",
    "\n",
    "#Modify format of the % of violence \n",
    "violence_per_region['%_Violence_Territory'] = violence_per_region['%_Violence_Territory']/100\n",
    "\n",
    "violence_per_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://note.nkmk.me/en/python-pandas-nan-judge-count/\n",
    "\n",
    "print( f'== Missing values for violence per region ==')\n",
    "violence_per_region.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_per_region['Perpetrator'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to filter the dataset in the columnc 'Pepetrators' and 'Datatype'\n",
    "def filter_and_replace(dataframe):\n",
    "    # Filter for rows where 'Type of violence' is 'physical or sexual'\n",
    "    dataframe = dataframe[dataframe['Type of violence'] == 'physical or sexual']\n",
    "    \n",
    "    # Replace 'current partner or former partner' with 'Partner/Ex Partner' in the 'Perpetrator' column\n",
    "    dataframe['Type of violence'] = dataframe['Type of violence'].replace('physical or sexual', 'Phisical/Sexual')\n",
    "    \n",
    "    # Filter for rows where 'Perpetrator' is 'current partner or former partner'\n",
    "    dataframe = dataframe[dataframe['Perpetrator'] == 'current partner or former partner']\n",
    "    \n",
    "    # Replace 'current partner or former partner' with 'Partner/Ex Partner' in the 'Perpetrator' column\n",
    "    dataframe['Perpetrator'] = dataframe['Perpetrator'].replace('current partner or former partner', 'Partner/Ex Partner')\n",
    "    \n",
    "    # Filter for rows where 'Data type' matches a specific condition\n",
    "    dataframe = dataframe[dataframe['Data type'] == 'women aged 16-70 years who have suffered violence lifetime (% of ever-partnered women 16-70 years)']\n",
    "    \n",
    "    # Replace 'current partner or former partner' with 'Partner/Ex Partner' in the 'Perpetrator' column\n",
    "    dataframe['Data type'] = dataframe['Data type'].replace('women aged 16-70 years who have suffered violence lifetime (% of ever-partnered women 16-70 years)', 'Victims 16-70 - lifetime')\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "violence_per_region = filter_and_replace(violence_per_region)\n",
    "\n",
    "violence_per_region =violence_per_region.loc[violence_per_region ['Territory'] != 'Italy']\n",
    "\n",
    "# Filter for rows where 'Perpetrator' is 'current partner or former partner'\n",
    "#violence_per_region = violence_per_region.loc[violence_per_region['Perpetrator'] == 'current partner or former partner']\n",
    "violence_per_region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_per_region['Data type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_per_region['Type of violence'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tuttitalia.it/statistiche/nord-centro-mezzogiorno-italia/\n",
    "# https://www.youtube.com/watch?app=desktop&v=8Y1UkY0oAXM\n",
    "#replace multiple values in position column\n",
    "replacements_regions = {\n",
    "    'Liguria': 'Nord',\n",
    "    'Lombardia': 'Nord',\n",
    "    'Piemonte': 'Nord',\n",
    "    \"Valle d'Aosta / Vallée d'Aoste\": 'Nord',\n",
    "    'Emilia-Romagna': 'Nord',\n",
    "    'Friuli-Venezia Giulia': 'Nord',\n",
    "    'Trentino Alto Adige / Südtirol': 'Nord',\n",
    "    'Veneto': 'Nord',\n",
    "    'Provincia Autonoma Bolzano / Bozen': 'Nord',\n",
    "    'Provincia Autonoma Trento': 'Nord',\n",
    "    'Lazio': 'Centre',\n",
    "    'Marche': 'Centre',\n",
    "    'Toscana': 'Centre',\n",
    "    'Umbria': 'Centre',\n",
    "    'Abruzzo': 'Sud',\n",
    "    'Basilicata': 'Sud',\n",
    "    'Calabria': 'Sud',\n",
    "    'Campania': 'Sud',\n",
    "    'Molise': 'Sud',\n",
    "    'Puglia': 'Sud',\n",
    "    'Sardegna': 'Sud',\n",
    "    'Sicilia': 'Sud',\n",
    "    'Basilicata': 'Sud',\n",
    "    'Calabria': 'Sud',\n",
    "    'Campania': 'Sud',\n",
    "    'Molise': 'Sud',\n",
    "    'Puglia': 'Sud',\n",
    "    'Sardegna': 'Sud',\n",
    "    'Sicilia': 'Sud',\n",
    "}\n",
    "\n",
    "violence_per_region['Territory'] = violence_per_region['Territory'].replace(replacements_regions)\n",
    "\n",
    "violence_per_region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_per_region_probability = violence_per_region.groupby('Territory')['%_Violence_Territory'].mean().reset_index()\n",
    "violence_per_region_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generata a dataframe of 200 lines for the variables \"Region\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://www.istat.it/it/files/2021/12/CENSIMENTO-E-DINAMICA-DEMOGRAFICA-2020.pdf\n",
    "\n",
    "nord_popolation = 0.464\n",
    "sud_population = 0.198\n",
    "centre_population = 0.338\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_list = [ 'Nord', 'Sud', 'Centre']\n",
    "data = np.random.choice(regions_list, p=[nord_popolation, sud_population, centre_population], size=200)\n",
    "violence_against_women = pd.DataFrame(data, columns=['Territory'])\n",
    "violence_against_women.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Education Level**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Probability of violence on womend devided per education level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_per_educational_level = pd.read_csv('DataSet/violence_per_educational_level.csv')\n",
    "violence_per_educational_level['Territory'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_per_educational_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_removed = ['ITTER107', 'Territory', 'TIPO_DATO_VIOLENZA', 'TIPOAUT', 'TIPOVIOLENZA', 'TITOLO_STUDIO', 'Select time', 'Flag Codes', 'Flags']\n",
    "\n",
    "# Remove the specified columns from the 'Instruction_level_italy' DataFrame\n",
    "violence_per_educational_level = violence_per_educational_level.drop(columns=columns_to_be_removed)\n",
    "\n",
    "#Rename columns TIME and Value for more clarity \n",
    "violence_per_educational_level = violence_per_educational_level.rename(columns={'TIME':'Year','Value':'%_Violence_Education', 'Educational level':'Education level' })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f'== Missing values for violence_per_educational_level ==')\n",
    "violence_per_educational_level.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the DataFrame to select specific rows based on conditions\n",
    "\n",
    "# call the function to filter and replace column 'Perpetrator' and 'DataType' previously defined\n",
    "violence_per_educational_level = filter_and_replace(violence_per_educational_level)\n",
    "# remove line total from educational level\n",
    "violence_per_educational_level = violence_per_educational_level.loc[violence_per_educational_level['Education level'] != 'total']\n",
    "\n",
    "violence_per_educational_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.all.html  \n",
    "# https://stackoverflow.com/questions/39768547/replace-whole-string-if-it-contains-substring-in-pandas\n",
    "# substitute the value that contain the word \"scuola\" in the education level column with 'Primary education'A\n",
    "violence_per_educational_level.loc[violence_per_educational_level['Education level'].str.contains('Primary school'), 'Education level'] = 'Primary Education'\n",
    "\n",
    "# substitute the value that contain the word \"laurea\" in the education level column with 'higher education'\n",
    "violence_per_educational_level.loc[violence_per_educational_level['Education level'].str.contains('university'), 'Education level'] = 'Higher Education'\n",
    "\n",
    "# substitute the value that contain the word \"diploma\" in the education level column with 'high school'\n",
    "violence_per_educational_level.loc[violence_per_educational_level['Education level'].str.contains('diploma'), 'Education level'] = 'High School'\n",
    "violence_per_educational_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_per_educational_level['%_Violence_Education'] = violence_per_educational_level['%_Violence_Education']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_educational_level_probability = violence_per_educational_level.groupby('Education level')['%_Violence_Education'].mean().reset_index()\n",
    "violence_educational_level_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  **Calculate the education level devided per regionr of women with age 15+ years**\n",
    "\n",
    "The purpose of this first part is to determine the percentage of women aged 15 and above with various levels of education devided per area of residence: the North, Central, and Southern regions.\n",
    "\n",
    "The data used for this estimation has been downloaded from the ISTAT website, which is the Italian Institute of Statistics, that leave avaiable to the public several datasets [[]](http://dati.istat.it/?lang=en). The selected dataset, titled \"Population 15 years and over by the highest level of education - previous regulation (until 2020),\" contains information on different levels of education for residents in Italy, reported in thousands, and provides insights into various demographic characteristics.\" \n",
    "\n",
    "\n",
    "    - Import the dataset\n",
    "\n",
    "First we need to import the needed library and the dataset with the numpy read_csv function [[]](https://www.w3schools.com/python/pandas/pandas_csv.asp).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the dataset \n",
    "# https://www.w3schools.com/python/pandas/pandas_csv.asp\n",
    "Education_level_italy = pd.read_csv('DataSet/Instruction_level_italy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Data Cleaning\n",
    "\n",
    "It is now important clean and elaborate the dataset to being.\n",
    "\n",
    "First I will check the dataset with the sample() function to investigate what columns we can drop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 5 rows  \n",
    "Education_level_italy.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon examining the dataset, I have identified several columns that can be removed because they are not relevant for the analysis or because they contain redundant information.\n",
    "\n",
    "These columns include: ['ITTER107', 'TIPO_DATO_FOL', 'SEXISTAT1', 'Tipo dato', 'ETA1', 'Classe di età', 'TITOLO_STUDIO', 'TIME', 'Flag Codes', 'Flags'].\n",
    "\n",
    "I will use the drop() function with a variable to specify which columns to remove and update the DataFrame accordingly. We can them check the first 5 columns of the dataset with the head() function to see if the removal was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to be removed from the DataFrame\n",
    "columns_to_be_removed = ['ITTER107', 'TIPO_DATO_FOL', 'SEXISTAT1', 'Tipo dato', 'ETA1', 'Classe di età', 'TITOLO_STUDIO', 'TIME', 'Flag Codes', 'Flags']\n",
    "\n",
    "# Remove the specified columns from the 'Instruction_level_italy' DataFrame\n",
    "Education_level_italy = Education_level_italy.drop(columns=columns_to_be_removed)\n",
    "\n",
    "# Display the first few rows of the modified DataFrame\n",
    "Education_level_italy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the colum name with a more understandacle meaning for english speaker using The rename() function [[]](https://www.kdnuggets.com/2022/11/4-ways-rename-pandas-columns.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns in a Pandas DataFrame\n",
    "Education_level_italy.rename(\n",
    "    columns={\"Territorio\": \"Territory\", \"Sesso\": \"Sex\", \"Titolo di studio\": \"Education level\",\"Seleziona periodo\": \"Year of observation\" },\n",
    "    inplace=True\n",
    ")\n",
    "# check the columns name of the dataset \n",
    "Education_level_italy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About the colum sex I will need to keep only female row. We can check the unique value with the function Unique()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the unique value in the column sex\n",
    "Education_level_italy['Sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the .loc [[]](https://deallen7.medium.com/using-pandas-loc-and-isin-to-filter-for-a-list-of-values-in-python-a1c862054058) function to select only the row with the specified value \"femmine,\" and then we will update the dataset accordingly. Finally, we will replace \"femmine\" with \"female [[]](https://datatofish.com/replace-values-pandas-dataframe/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the rows with value \"femmmine\" in the sex colum\n",
    "Education_level_italy = Education_level_italy.loc[Education_level_italy['Sex'] == 'femmine']\n",
    "# replace \"femmine\" with \"female\"\n",
    "Education_level_italy['Sex']=Education_level_italy['Sex'].replace(\"femmine\", \"Female\")\n",
    "# check unique value \n",
    "Education_level_italy['Sex'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'Region' column, after conducting a unique() analysis, revealed redundant values. \n",
    "'Italy,' 'Nord est,' and 'Nord Ovest' are already encompassed within 'Nord,' 'Centro' (Centre), and 'Mezzogiorno' (South). Consequently, I will remove the unnecessary values and rename the remaining rows for better clarity [[]](https://datatofish.com/replace-values-pandas-dataframe/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of values to be selected from the 'Region' column\n",
    "filter_list = ['Nord-est', 'Nord-ovest', 'Italia']\n",
    "\n",
    "# Filter the DataFrame 'Instruction_level_italy' to exclude rows where 'Territorio' is in the 'filter_list'\n",
    "Education_level_italy = Education_level_italy.loc[~Education_level_italy['Territory'].isin(filter_list)]\n",
    "\n",
    "# replace mezzogiorno and centro\n",
    "\n",
    "Education_level_italy['Territory'] = Education_level_italy['Territory'].replace({\"Mezzogiorno\": \"Sud\", \"Centro\": \"Centre\"})\n",
    "# check the removal and replacement with the group by function \n",
    "filtered_grouped_data = Education_level_italy.groupby('Territory')['Value'].sum().reset_index()\n",
    "print(filtered_grouped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the column \"Year\", after visualising the content, I decide to keep only the more recent observation that refer to the whole 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the rows with value \"2020\" in the 'Year of observation' column\n",
    "Education_level_italy = Education_level_italy.loc[Education_level_italy['Year of observation'] == '2020']\n",
    "\n",
    "# display the unique value using the group by column \n",
    "Education_level_italy.groupby('Year of observation')['Value'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns represent the five different levels of education that can be attained in Italy. However, for this analysis, I intend to categorize them into the following three main levels:\n",
    "\n",
    "- Primary education: Individuals who have completed only primary school education (typically up to 13 years of age).\n",
    "- High school education: Individuals who have successfully completed high school (typically up to 19 years of age).\n",
    "- Higher education: This category encompasses all forms of higher education, including degrees, bachelor's degrees, master's degrees, PhDs, and more.\n",
    "\n",
    "The replace will be done with the pandas metho str.contain [[]](http://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.contains.html), [[]](https://stackoverflow.com/questions/39768547/replace-whole-string-if-it-contains-substring-in-pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# https://stackoverflow.com/questions/39768547/replace-whole-string-if-it-contains-substring-in-pandas\n",
    "# substitute the value that contain the word \"scuola\" in the education level column with 'Primary education'A\n",
    "Education_level_italy.loc[Education_level_italy['Education level'].str.contains('scuola'), 'Education level'] = 'Primary Education'\n",
    "\n",
    "# substitute the value that contain the word \"diploma\" in the education level column with 'high school'\n",
    "Education_level_italy.loc[Education_level_italy['Education level'].str.contains('diploma'), 'Education level'] = 'High School'\n",
    "\n",
    "# substitute the value that contain the word \"laurea\" in the education level column with 'higher education'\n",
    "Education_level_italy.loc[Education_level_italy['Education level'].str.contains('laurea'), 'Education level'] = 'Higher Education'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can remove the 'total' column, as it is redundant, and group the dataset by education level. \n",
    "The removal will be done using the .loc function  [[]](https://www.shanelynn.ie/pandas-drop-delete-dataframe-rows-columns/) which will find all the values that don't match the given date, and the dataset will be updated accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame 'Instruction_level_italy' to exclude rows where 'Territorio' is in the 'filter_list'\n",
    "# https://www.shanelynn.ie/pandas-drop-delete-dataframe-rows-columns/\n",
    "Education_level_italy = Education_level_italy.loc[Education_level_italy['Education level'] != 'totale']\n",
    "\n",
    "# Group by the dataset based on unique value of the column 'Education level'\n",
    "Education_level_italy = Education_level_italy.groupby(['Territory', 'Sex', 'Education level', 'Year of observation'])['Value'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split the datases on three different dataset, one for each region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Education_level_italy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Education_level_italy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the probability of each level of education divided by region. We use the *groupby* operation to group the data by the 'Region' column and calculate the sum of the values for each group. Afterward, we utilize the *map* [[]](https://www.geeksforgeeks.org/python-map-function/) function to create a new column, 'Probability%', based on the total value of the corresponding region.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by 'Region' and calculate the sum of 'Value' for each group\n",
    "region_groups = Education_level_italy.groupby('Territory')['Value'].sum()\n",
    "\n",
    "# Calculate the probability percentage for each region\n",
    "# https://sparkbyexamples.com/pandas/pandas-map-function-explained/\n",
    "# https://practicaldatascience.co.uk/data-science/how-to-use-the-pandas-map-function\n",
    "Education_level_italy['%_Education_level'] = Education_level_italy['Value'] / Education_level_italy['Territory'].map(region_groups)\n",
    "Education_level_italy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Education_level_italy by 'Region'\n",
    "grouped_education = Education_level_italy.groupby('Territory')['%_Education_level']\n",
    "\n",
    "Education_List = ['High School', 'Primary Education', 'Higher Education']\n",
    "\n",
    "# Define a function to sample education levels based on probabilities for each region\n",
    "def Education_level(row):\n",
    "    region = row['Territory']\n",
    "    probabilities = grouped_education.get_group(region).values\n",
    "    education = np.random.choice(Education_List, p=probabilities)\n",
    "    return education\n",
    "\n",
    "# Apply the function to create the 'Education' column\n",
    "violence_against_women[\"Education level\"] = violence_against_women.apply(Education_level, axis=1)\n",
    "\n",
    "violence_against_women "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupancy level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Percentage of violence against women by occupancy level**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_per_labour_status = pd.read_csv('DataSet/Violence per labour status.csv')\n",
    "violence_per_labour_status.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to be removed from the DataFrame\n",
    "columns_to_be_removed = ['ITTER107', 'TIPO_DATO_VIOLENZA', 'TIPOAUT',\n",
    "       'TIPOVIOLENZA', 'CITTADINANZA', 'Citizenship', 'CONDIZIONE_DICH4',\n",
    "       'TIME', 'Flag Codes', 'Flags']\n",
    "\n",
    "# Remove the specified columns from the 'Instruction_level_italy' DataFrame\n",
    "violence_per_labour_status = violence_per_labour_status.drop(columns=columns_to_be_removed)\n",
    "\n",
    "# Renaming columns in a Pandas DataFrame\n",
    "violence_per_labour_status.rename(\n",
    "    columns={'TIME': \"Year\", \n",
    "             'Labour and professional status': 'Professional Status',\n",
    "             'Value':'%_violence_labour'\n",
    "        },  inplace=True)\n",
    "\n",
    "violence_per_labour_status['%_violence_labour'] = violence_per_labour_status['%_violence_labour']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the DataFrame to select specific rows based on conditions\n",
    "\n",
    "# call the function to filter and replace column 'Perpetrator' and 'DataType' previously defined\n",
    "violence_per_labour_status = filter_and_replace(violence_per_labour_status)\n",
    "\n",
    "# remove line all items from educational level\n",
    "violence_per_labour_status = violence_per_labour_status.loc[violence_per_labour_status['Professional Status'] != 'all items']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace labour values on occupied and unoccupied \n",
    "replacements_labour_status= {\n",
    "    'seeking for job': 'Unoccupied',\n",
    "    'executive, employer, professional': 'Occupied',\n",
    "    'blu collar, apprentice':'Occupied',\n",
    "    'self-employed, family worker, co.co.co.':'Occupied',\n",
    "    'housewife':'Unoccupied',\n",
    "    'student':'Unoccupied',\n",
    "    'other condition (different from housewife,student,seeking for job,retired)':'AssertionErrorUnoccupied',\n",
    "    'retired':'Occupied',\n",
    "    'middle management, white collar':'Occupied'\n",
    "}\n",
    "\n",
    "\n",
    "violence_per_labour_status['Professional Status'] = violence_per_labour_status['Professional Status'].replace(replacements_labour_status)\n",
    "violence_per_labour_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_per_labour_statu_probability = violence_per_labour_status.groupby('Professional Status')['%_violence_labour'].mean().reset_index()\n",
    "\n",
    "violence_per_labour_statu_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **calculate the percentage of occupancy in italy per region/level of education**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset - Occupancy data set \n",
    "\n",
    "occupancy_rate = pd.read_csv('DataSet/Occupancy data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_rate.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupancy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to be removed from the DataFrame\n",
    "columns_to_be_removed = ['FREQ', 'Frequency', 'REF_AREA', 'DATA_TYPE', 'Indicator',\n",
    "       'SEX', 'AGE', 'EDU_LEV_HIGHEST', 'OBS_STATUS', 'Observation status']\n",
    "\n",
    "# Remove the specified columns from the 'Instruction_level_italy' DataFrame\n",
    "occupancy_rate = occupancy_rate.drop(columns=columns_to_be_removed)\n",
    "\n",
    "# Renaming columns in a Pandas DataFrame\n",
    "occupancy_rate.rename(\n",
    "    columns={\"Time (TIME_PERIOD)\": \"Year\",\n",
    "            \"Age (DESC)\": 'Age',\n",
    "            \"Highest level of education attained\":\"Education level\",\n",
    "            'Sex (DESC)': 'Sex',\n",
    "            'Observation' : '%_occupation'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "occupancy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of values to be selected from the 'Territity' column\n",
    "filter_list = ['Nord-est', 'Nord-ovest', 'Italy']\n",
    "\n",
    "# Filter the DataFrame 'Instruction_level_italy' to exclude rows where 'Territorio' is in the 'filter_list'\n",
    "occupancy_rate = occupancy_rate.loc[~occupancy_rate['Territory'].isin(filter_list)]\n",
    "\n",
    "# Filter for rows where 'Year' is '2020'\n",
    "occupancy_rate = occupancy_rate.loc[occupancy_rate['Year']=='2022']\n",
    "\n",
    "# Filter for rows where 'Sex' is 'Females'\n",
    "occupancy_rate = occupancy_rate.loc[occupancy_rate['Sex']=='Females']\n",
    "\n",
    "# Filter for rows where 'Age' is '15-74' years\n",
    "occupancy_rate = occupancy_rate.loc[occupancy_rate['Age']=='15-74 years']\n",
    "\n",
    "# Filter for rows where 'Educational Level' is not 'Total'\n",
    "occupancy_rate = occupancy_rate.loc[occupancy_rate[\"Education level\"]!='Total ']\n",
    "\n",
    "occupancy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename value in the 'Educational level' column for a better clarity\n",
    "occupancy_rate[\"Education level\"] = occupancy_rate[\"Education level\"].replace({\n",
    "    \"'No educational degree  primary and lower secondary school certificate'\": 'Primary Education',\n",
    "    'Upper and post secondary ': 'High School',\n",
    "    \"'Tertiary (university  doctoral and specialization courses)'\": 'Higher Education'\n",
    "})\n",
    "\n",
    "# rename value in the 'Territory' column for a better clarity\n",
    "occupancy_rate[\"Territory\"] = occupancy_rate[\"Territory\"].replace({\n",
    "    \"Centro (I)\": 'Centre',\n",
    "    'Mezzogiorno': 'Sud',\n",
    "})\n",
    "occupancy_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 'violence_against_women' by 'Territory' and 'Educational level'\n",
    "grouped_occupancy_region = occupancy_rate.groupby(['Territory', 'Education level'])['%_occupation']\n",
    "\n",
    "def Occupancy_level(row):\n",
    "    # Extract 'Territory' and 'Educational level' from the current row\n",
    "    row_combination = (row['Territory'], row['Education level'])\n",
    "    \n",
    "    # Check if the row_combination is present in the grouped data\n",
    "    if row_combination in grouped_occupancy_region.groups:\n",
    "        # Retrieve the first value of '%_occupation' for the corresponding group\n",
    "        rate_of_occupancy = grouped_occupancy_region.get_group(row_combination).values[0]/100\n",
    "        occupation_binomial = np.random.binomial(1, p=rate_of_occupancy)\n",
    "        occupation = \"Occupied\" if occupation_binomial == 1 else \"Unoccupied\"\n",
    "        return occupation \n",
    "  \n",
    "\n",
    "# Apply the function to all rows and create a new column '%_of_occupation' in 'violence_against_women'\n",
    "violence_against_women[\"Professional Status\"] = violence_against_women.apply(Occupancy_level, axis=1)\n",
    "violence_against_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://note.nkmk.me/en/python-pandas-nan-judge-count/\n",
    "\n",
    "print( f'== Missing values for violence per region ==')\n",
    "violence_against_women.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marital status "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probability of violence for marital status "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_marital_status = pd.read_csv('DataSet/Marital Status.csv')\n",
    "violence_marital_status.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to be removed from the DataFrame\n",
    "columns_to_be_removed = ['FREQ', 'Frequency', 'REF_AREA', 'Territory', 'DATA_TYPE',\n",
    "       'PERPETRATOR', 'TYPE_VIOLENCE', 'MARITAL_STATUS_WOMAN', 'OBS_STATUS', 'Observation status']\n",
    "\n",
    "# Remove the specified columns from the 'Instruction_level_italy' DataFrame\n",
    "violence_marital_status = violence_marital_status.drop(columns=columns_to_be_removed)\n",
    "\n",
    "# Renaming columns in a Pandas DataFrame\n",
    "violence_marital_status.rename(\n",
    "    columns={'Time (TIME_PERIOD)': \"Year\", \n",
    "             'Perpetrator (DESC)': 'Perpetrator',\n",
    "             'Observation' : '%_Marital_Status',\n",
    "             'Marital status woman':'Marital Status'},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "violence_marital_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_marital_status['Perpetrator'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for rows where 'Type of violence' is 'Physical or sexual'\n",
    "violence_marital_status = violence_marital_status.loc[violence_marital_status['Type of violence'] == 'Physical or sexual']\n",
    "\n",
    "# Filter for rows where 'Perpetrator' is 'Current partner or former partner'\n",
    "violence_marital_status = violence_marital_status.loc[violence_marital_status['Perpetrator'] == 'Current partner or former partner']\n",
    "\n",
    "# Filter for rows where 'Indicator' is 'Women aged 16-70 years who have suffered violence in the past 12 months (% of ever-partnered women 16-70 years)'\n",
    "violence_marital_status = violence_marital_status.loc[violence_marital_status['Indicator'] == 'Women aged 16-70 years who have suffered violence in the past 5 years (% of ever-partnered women 16-70 years)']\n",
    "\n",
    "# Filter for rows where 'Marital status woman' is not 'Total'\n",
    "violence_marital_status = violence_marital_status.loc[violence_marital_status['Marital Status'] != 'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace labour values on occupied and unoccupied \n",
    "replacements= {\n",
    "    'Women aged 16-70 years who have suffered violence in the past 5 years (% of ever-partnered women 16-70 years)': 'Victims 16-70 in the last 5 years',\n",
    "    'Single persons (never married and never in same sex civil partnership)': 'Single',\n",
    "    'Married persons' : 'Married',                                                       \n",
    "    'Divorced persons' : 'Divorced',                                                     \n",
    "    'Widowed persons' : 'Widowed',\n",
    "    'Current partner or former partner':'Partner/Ex Partner'\n",
    "   \n",
    "}\n",
    "\n",
    "\n",
    "violence_marital_status = violence_marital_status.replace(replacements)\n",
    "violence_marital_status\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_marital_status['%_Marital_Status'] = violence_marital_status['%_Marital_Status']/100\n",
    "violence_marital_status_probability = violence_marital_status.groupby('Marital Status')['%_Marital_Status'].sum().reset_index()\n",
    "violence_marital_status_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution between single/married and wedow in Italy devided by region "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code https://www.geeksforgeeks.org/construct-a-dataframe-in-pandas-using-string-data/\n",
    "# data http://www.comuni-italiani.it/statistiche/coniugati.html\n",
    "import io\n",
    "\n",
    "data = \"\"\"\n",
    "Territory Unmarried Married Divorced Widowed Total\n",
    "Puglia 1680431 2047771 59777 275909 4063888\n",
    "Basilicata 233063 283826 8108 45368 570365\n",
    "Molise 125197 154426 4608 26218 310449\n",
    "Abruzzo 534579 655591 27093 104984 1322247\n",
    "Sicilia 2122407 2493149 78610 362475 5056641\n",
    "Calabria 826606 968893 24960 144669 1965128\n",
    "Campania 2523006 2853658 75166 387254 5839084\n",
    "Umbria 361138 431497 22299 73974 888908\n",
    "Marche 636481 741108 36403 124063 1538055\n",
    "Toscana 1538464 1792460 107568 303945 3742437\n",
    "Veneto 2080718 2336002 136439 354370 4907529\n",
    "Piemonte 1771528 2090721 164131 366146 4392526\n",
    "FriuliVeneziaGiulia 490888 572662 48255 106067 1217872\n",
    "Lombardia 4318788 4680254 300759 719365 10019166\n",
    "Lazio 2566807 2744813 177640 408864 5898124\n",
    "Liguria 624489 726605 67158 147055 1565307\n",
    "Sardegna 740771 759875 35809 116680 1653135\n",
    "EmiliaRomagna 1917061 2037025 150809 343946 4448841\n",
    "Valled'Aosta 56546 54971 5499 9867 126883\n",
    "TrentinoAltoAdige 506054 457265 32706 66835 1062860\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Read the data into a DataFrame\n",
    "marital_stausu_distribution = pd.read_csv(io.StringIO(data), delimiter=\"\\s+\")\n",
    "\n",
    "# Display the DataFrame\n",
    "marital_stausu_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tuttitalia.it/statistiche/nord-centro-mezzogiorno-italia/\n",
    "# https://www.youtube.com/watch?app=desktop&v=8Y1UkY0oAXM\n",
    "#replace multiple values in position column\n",
    "replacements_regions = {\n",
    "    'Liguria': 'Nord',\n",
    "    'Lombardia': 'Nord',\n",
    "    'Piemonte': 'Nord',\n",
    "    \"Valled'Aosta\": 'Nord',\n",
    "    'EmiliaRomagna': 'Nord',\n",
    "    'FriuliVeneziaGiulia': 'Nord',\n",
    "    'TrentinoAltoAdige': 'Nord',\n",
    "    'Veneto': 'Nord',\n",
    "    'Lazio': 'Centre',\n",
    "    'Marche': 'Centre',\n",
    "    'Toscana': 'Centre',\n",
    "    'Umbria': 'Centre',\n",
    "    'Abruzzo': 'Sud',\n",
    "    'Basilicata': 'Sud',\n",
    "    'Calabria': 'Sud',\n",
    "    'Campania': 'Sud',\n",
    "    'Molise': 'Sud',\n",
    "    'Puglia': 'Sud',\n",
    "    'Sardegna': 'Sud',\n",
    "    'Sicilia': 'Sud',\n",
    "    'Basilicata': 'Sud',\n",
    "    'Calabria': 'Sud',\n",
    "    'Campania': 'Sud',\n",
    "    'Molise': 'Sud',\n",
    "    'Puglia': 'Sud',\n",
    "    'Sardegna': 'Sud',\n",
    "    'Sicilia': 'Sud',\n",
    "}\n",
    "\n",
    "marital_stausu_distribution['Territory'] = marital_stausu_distribution['Territory'].replace(replacements_regions)\n",
    "marital_stausu_distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_stausu_distribution = marital_stausu_distribution.groupby('Territory')[['Unmarried', 'Married', 'Divorced', 'Widowed', 'Total']].sum().reset_index()\n",
    "marital_stausu_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_stausu_distribution['Unmarried(%)'] = marital_stausu_distribution['Unmarried']/marital_stausu_distribution['Total']\n",
    "\n",
    "marital_stausu_distribution['Married(%)'] = marital_stausu_distribution['Married']/marital_stausu_distribution['Total']\n",
    "\n",
    "marital_stausu_distribution['Divorced(%)'] = marital_stausu_distribution['Divorced']/marital_stausu_distribution['Total']\n",
    "\n",
    "marital_stausu_distribution['Widowed(%)'] = marital_stausu_distribution['Widowed']/marital_stausu_distribution['Total']\n",
    "\n",
    "# List of columns to be removed from the DataFrame\n",
    "columns_to_be_removed = ['Unmarried', 'Married', 'Divorced', 'Widowed', 'Total']\n",
    "\n",
    "# Remove the specified columns from the 'Instruction_level_italy' DataFrame\n",
    "marital_status_distribution_probability = marital_stausu_distribution.drop(columns=columns_to_be_removed)\n",
    "\n",
    "marital_status_distribution_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_status_distribution_probability.values\n",
    "\n",
    "Education_List = ['Unmarried', 'Married', 'Divorced', 'Widowed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_against_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = marital_status_distribution_probability.loc[marital_status_distribution_probability['Territory'] == 'Nord']\n",
    "prob = probability.loc[:, 'Unmarried(%)':]\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = marital_status_distribution_probability.loc[marital_status_distribution_probability['Territory'] == 'Nord']\n",
    "prob = probability.loc[:, 'Unmarried(%)':]\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "marital_status_distribution_probability = marital_stausu_distribution.groupby('Territory')[['Unmarried(%)', 'Married(%)', 'Divorced(%)', 'Widowed(%)']].mean().reset_index()\n",
    "marital_status_list = ['Single', 'Married', 'Divorced', 'Widowed']\n",
    "\n",
    "# Create a function to generate random marital statuses based on probabilities\n",
    "def generate_marital_status(row):\n",
    "    region = row['Territory']\n",
    "    probability = marital_status_distribution_probability.loc[marital_status_distribution_probability['Territory'] == region]\n",
    "    #https://www.geeksforgeeks.org/flatten-a-list-of-dataframes/\n",
    "    prob = probability.loc[:, 'Unmarried(%)':].values.flatten()\n",
    "    return np.random.choice(marital_status_list, p=prob)\n",
    "\n",
    "# Apply the function to create the 'Married Status' column\n",
    "violence_against_women['Marital Status'] = violence_against_women.apply(generate_marital_status, axis=1)\n",
    "\n",
    "violence_against_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_against_women['Marital Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Join Column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(violence_against_women, violence_educational_level_probability, violence_per_region_probability, violence_per_labour_statu_probability, violence_marital_status_probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_against_women['Marital Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_educational_level_probability.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_marital_status_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames\n",
    "violence_against_women_congiunted__probability = violence_against_women.merge(\n",
    "    violence_educational_level_probability,\n",
    "    on='Education level',\n",
    ")\n",
    "\n",
    "violence_against_women_congiunted__probability = violence_against_women_congiunted__probability.merge(\n",
    "    violence_per_region_probability,\n",
    "    on='Territory',\n",
    ")\n",
    "\n",
    "violence_against_women_congiunted__probability = violence_against_women_congiunted__probability.merge(\n",
    "    violence_per_labour_statu_probability,\n",
    "    on='Professional Status',\n",
    ")\n",
    "\n",
    "violence_against_women_congiunted__probability = violence_against_women_congiunted__probability.merge(\n",
    "    violence_marital_status_probability,\n",
    "    on='Marital Status',\n",
    ")\n",
    "\n",
    "\n",
    "violence_against_women_congiunted__probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_against_women_congiunted__probability.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f'== Missing values for violence per region ==')\n",
    "violence_against_women_congiunted__probability.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_against_women_congiunted__probability['Congiunted_probability_violence']= (\n",
    "    violence_against_women_congiunted__probability['%_Violence_Education']\n",
    "    *violence_against_women_congiunted__probability['%_Violence_Territory']\n",
    "    *violence_against_women_congiunted__probability['%_violence_labour']\n",
    "    *violence_against_women_congiunted__probability['%_Marital_Status']\n",
    ")\n",
    "\n",
    "violence_against_women_congiunted__probability['Congiunted_probability_violence'] = (\n",
    "    violence_against_women_congiunted__probability['Congiunted_probability_violence']\n",
    "    /violence_against_women_congiunted__probability['Congiunted_probability_violence'].sum()\n",
    ")\n",
    "violence_against_women_congiunted__probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html\n",
    "#violence_against_women_congiunted__probability = violence_against_women_congiunted__probability.drop_duplicates()\n",
    "\n",
    "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n",
    "violence_against_women_congiunted__probability.sort_values(by=['Territory', 'Education level','Professional Status',\t'Marital Status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_against_women_congiunted__probability.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_be_removed = ['%_Violence_Territory', '%_violence_labour',\n",
    "       '%_Marital_Status', '%_Violence_Education']\n",
    "\n",
    "# Remove the specified columns from the 'Instruction_level_italy' DataFrame\n",
    "violence_against_women_congiunted__probability = violence_against_women_congiunted__probability.drop(columns=columns_to_be_removed)\n",
    "\n",
    "#https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html\n",
    "violence_against_women_congiunted__probability.sort_values(by=['Territory', 'Education level','Professional Status',\t'Marital Status']).reset_index()\n",
    "\n",
    "violence_against_women_congiunted__probability \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = violence_against_women_congiunted__probability['Congiunted_probability_violence']\n",
    "violence_against_women_congiunted__probability['Violence_lifetime'] = np.random.binomial(1, p=probability)\n",
    "violence_against_women_congiunted__probability.loc[violence_against_women_congiunted__probability['Violence_lifetime'] == 1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate violence yes or no "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violence_against_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group 'violence_against_women' by 'Territory' and 'Educational level'\n",
    "grouped_occupancy_region = occupancy_rate.groupby(['Territory', 'Education level'])['%_occupation']\n",
    "\n",
    "def Occupancy_level(row):\n",
    "    # Extract 'Territory' and 'Educational level' from the current row\n",
    "    row_combination = (row['Territory'], row['Education level'])\n",
    "    \n",
    "    # Check if the row_combination is present in the grouped data\n",
    "    if row_combination in grouped_occupancy_region.groups:\n",
    "        # Retrieve the first value of '%_occupation' for the corresponding group\n",
    "        rate_of_occupancy = grouped_occupancy_region.get_group(row_combination).values[0]/100\n",
    "        occupation_binomial = np.random.binomial(1, p=rate_of_occupancy)\n",
    "        occupation = \"Occupied\" if occupation_binomial == 1 else \"Unoccupied\"\n",
    "        return occupation \n",
    "  \n",
    "\n",
    "# Apply the function to all rows and create a new column '%_of_occupation' in 'violence_against_women'\n",
    "violence_against_women[\"Professional Status\"] = violence_against_women.apply(Occupancy_level, axis=1)\n",
    "violence_against_women"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pythoninoffice.com/replicate-excel-vlookup-hlookup-xlookup-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creiamo un dataframe di esempio\n",
    "data = {\n",
    "    'Occupazione': ['Impiegato', 'Studente', 'LiberoProfessionista'],\n",
    "    'Regione': ['Nord', 'Sud', 'Centro'],\n",
    "    'LivelloScolastico': ['Medio', 'Superiore', 'Universitario'],\n",
    "    'StatoMaritale': ['Single', 'Sposato', 'Divorziato'],\n",
    "    'ProbabilitaOccupazione': [0.4, 0.3, 0.3],\n",
    "    'ProbabilitaRegione': [0.4, 0.2, 0.4],\n",
    "    'ProbabilitaLivelloScolastico': [0.3, 0.4, 0.3],\n",
    "    'ProbabilitaStatoMaritale': [0.5, 0.3, 0.2],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Creiamo il vettore di probabilità congiunta approssimata assumendo indipendenza\n",
    "df['ProbabilitaCongiunta'] = (\n",
    "    df['ProbabilitaOccupazione']\n",
    "    * df['ProbabilitaRegione']\n",
    "    * df['ProbabilitaLivelloScolastico']\n",
    "    * df['ProbabilitaStatoMaritale']\n",
    ")\n",
    "\n",
    "# Generate the column 'HaSubitoViolenza' based on the joint probability\n",
    "np.random.seed(42)  # To make random generation reproducible\n",
    "df['HaSubitoViolenza'] = np.random.choice([0, 1], size=len(df), p=df['ProbabilitaCongiunta'])\n",
    "\n",
    "# Print the resulting dataframe\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
